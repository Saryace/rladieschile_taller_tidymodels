---
title: "Taller Tidymodels"
subtitle: "R-Ladies Chile\n(Valparaíso + Santiago + Talca + Concepción)"
author: "[Sara Acevedo](https://twitter.com/saryace)"
format: 
  rladies-revealjs:
    footer: "[R-Ladies](https://rladies.org/) tema para [Quarto Presentations](https://quarto.org/docs/presentations/revealjs/index.html). Autora [Bea Milz](https://twitter.com/BeaMilz) Código disponible en [GitHub](https://github.com/beatrizmilz/quarto-rladies-theme)."
from: markdown+emoji
embed-resources: true
---

# Hola!

{{< fa brands twitter size=1.4xl >}} [saryace](https://github.com/Saryace) | {{< fa brands github size=1.4xl >}} [Saryace](https://twitter.com/saryace) | {{< fa globe size=1.4xl >}} [saryace.github.io](saryace.github.io)

::: {.incremental}

- Sara Acevedo
- Doctora en Ciencias de la Ingeniería UC
- Magíster UC-Davis
- Usuaria de R hace años :woman_technologist:
- Clases y proyectos

:::

# Hola!

{{< fa brands twitter size=1.4xl >}} [soilbiophysics1](https://twitter.com/@soilbiophysics1) |
{{< fa globe size=1.4xl >}} [website](ing.puc.cl/biofisica) |
{{< fa brands instagram size=1.4xl >}} [soilbiophysicslab](instagram.com/soilbiophysicslab) 

::: {.incremental}

- Laboratorio de Biofísica de Suelos
- Estudiamos como el agua se relaciona con el suelo y plantas
- Temas: erosión, retención de humedad e incendios

:::

## Qué aprenderemos en este taller :computer:

::: box

El megapaquete (o framework) **tidymodels** contiene un set de paquetes para la <span class="fragment highlight-blue" fragment-index=1>modelación</span> y <span class="fragment highlight-red" fragment-index=2>uso de machine learning</span> usando los principios de **tidyverse**

:::

::: {.incremental}
- {{< fa brands r-project size=1.4xl >}} **Manejo de datos** usando tidyverse
- {{< fa brands r-project size=1.4xl >}} **Graficar** usando ggplot2
- {{< fa brands r-project size=1.4xl >}} **Modelar** info usando tidymodels
::: 

## Qué NO veremos en este taller :computer:

::: {.incremental}
- {{< fa brands r-project size=1.4xl >}} **Descripción de los modelos**: por tiempo ya que alta variedad de modelos y algoritmos
- {{< fa brands r-project size=1.4xl >}} **Revisión conceptos estadísticos**: uso del paquete broom será parte de otro taller

:::

## Código y materiales

Las presentaciones contienen código real (se puede copiar y pegar directamente). El repositorio contendrá el material y contenido del taller

```{r}
#| eval: false
#| echo: true
1 + 1 # copia y pega en la consola
```
::: info-box

El repositorio lo puedes encontrar acá:

<center>
<i class="fa-solid fa-book"></i> [Repositorio en github: R-LadiesChile](https://github.com/rladieschile/rladieschile_taller_tidymodels)
</center>
<center>
<i class="fa-solid fa-book"></i> [Repositorio en github: Saryace](https://github.com/Saryace/rladieschile_taller_tidymodels)
</center>

:::

## La filosofía del paquete tidymodels y tidyverse

* Reusar estructuras de datos
* Utilizar el operador `pipe %>% ` para combinar funciones
* Pensado para "humanos"


## Ejemplo: un pedazo de torta a partir de ingredientes

::: {.incremental}
- Ingredientes (harina, azúcar, etc.) 🛒
- Mezclar en un bowl ingredientes 🥣
- Hornear la mezcla ⏲️
- Decorar el bizcocho 🥧
- Cortar 🍰
:::

## Estilo Tidyverse

```{r}
#| eval: false
#| echo: true
comprar(ingredientes = c((harina,azucar))) %>%
mezclar() %>% 
hornear() %>% 
decorar() %>% 
cortar()
```

::: box

Tanto **tidymodels** como **tidyverse** comparten este estilo

:::

[Idea de Arthur Welles @ArthurWelle](https://twitter.com/ArthurWelle)

## Antes de comenzar: instalación de paquetes

Copiar y pegar en la consola el siguiente chunk de código

```{r install}
#| eval: false
#| echo: true
install.packages(c("tidymodels",
                   "datos",
                   "workflows",
                   "workflowsets"))
```

## Antes de comenzar: créditos y más información

- Tema de la presentación: [Bea Milz](https://twitter.com/BeaMilz)
- Ideas para el taller:
  - [D-Lab UCBerkeley](https://github.com/dlab-berkeley)
  - [Tidy Modeling with R, Max Kuhn y Julia Silge](https://www.tmwr.org/)

## Comenzamos cargando un set de datos

Tamaño de pingüinos adultos en busca de comida cerca de la estación Palmer en la Antártica

```{r}

library(tidyverse)
library(datos)
library(tidymodels)
library(workflows)
library(workflowsets)

pinguinos <- datos::pinguinos
pinguinos
```

## Un problema 

::: {.incremental}
- Los pingüinos no se pueden manipular, solo se puede medir sus aletas a distancia

- Nos preguntamos si podemos predecir la masa de los pingüinos a partir del largo de las aletas y pico.

- Algo de estadística básica: la medida de la aletas es la variable independiente `x` y la masa es la variable dependiente `y`. 
::: 

## Un par de definiciones

::: {.incremental}
- Como conocemos los valores de `x` e `y`, este problema se aplica ML **supervisado** (existe ML no-supervisado)

- Como la predicción es un variable continua (masa), es un problema de **regresión** (existe también la clasificación)

::: 

## Como comenzar a modelar?

- Análisis exploratorio de datos

- Creación de un conjunto de entrenamiento y testeo

- Decidir si y cómo preprocesar los datos para que sean apropiados para la modelación

- Creación y ajuste de modelos en un conjunto de entrenamiento

- Evaluación de los modelos según los parámetros seleccionados

- Perfeccionamiento de los modelos

- Evaluación del modelo elegido con el conjunto de testeo

[Tidy Modeling with R, Max Kuhn y Julia Silge](https://www.tmwr.org/)

## Análisis exploratorio de datos

Por tiempo, no lo veremos en profundidad, pero conocer sobre los datos nos ayuda a crear mejores modelos

```{r}
#| echo: true
dplyr::glimpse(pinguinos)
```

## Análisis exploratorio de datos

```{r}
#| echo: true
#| output-location: slide

pinguinos %>%
  drop_na() %>% 
      ggplot(aes(x = masa_corporal_g,
                 y = largo_aleta_mm)) +
      geom_point(alpha = 0.3) +
      labs(
      x = "masa corporal en gramos",
      y = "largo aleta",
      title = "Análisis exploratorio masa pinguinos",
      subtitle = "Masa vs largo aleta"
      ) +
  theme_bw()
```

## Creación de un conjunto de entrenamiento y prueba

El paquete `rsample` posee funciones para crear los sets de entrenamiento y testeo

```{r}
#| echo: true
set.seed(2023)

pinguinos_division <- rsample::initial_split(pinguinos, prop = 0.80, strata = masa_corporal_g)

pinguinos_entrenamiento <- rsample::training(pinguinos_division)

pinguinos_testeo  <-  rsample::testing(pinguinos_division)
```

## Creación de un conjunto de entrenamiento y prueba

El paquete `rsample` posee funciones para crear los sets de **entrenamiento** y testeo

```{r}
#| echo: true

dplyr::glimpse(pinguinos_entrenamiento)

```

## Creación de un conjunto de entrenamiento y prueba

El paquete `rsample` posee funciones para crear los sets de entrenamiento y **testeo**

```{r}
#| echo: true

dplyr::glimpse(pinguinos_testeo)

```

## Decidir si y cómo preprocesar los datos para que sean apropiados para la modelación

Depende de los datos y de los tipos de modelos. Pero el paquete `recipes` tiene muchas opciones. Ejemplos de preprocesamiento:

- Datos ausentes
- Datos categóricos
- Transformaciones (centrar, escalar, etc.)

## Decidir si y cómo preprocesar los datos para que sean apropiados para la modelación

![](img/preprocessing.png){fig-align="center"}
---

## Decidir si y cómo preprocesar los datos para que sean apropiados para la modelación

```{r}
#| echo: true
receta_pinguinos <-
  recipe(masa_corporal_g ~ largo_aleta_mm + largo_pico_mm,
        data = pinguinos_entrenamiento) %>%
  step_impute_mean(masa_corporal_g,
                   largo_aleta_mm,
                   largo_pico_mm)

receta_pinguinos
```

## Creación y ajuste de modelos en un conjunto de entrenamiento

Esto lo haremos con los paquete `workflows` y `parsnip`. Debemos indicar que modelo y receta usar en el conjunto de entrenamiento

```{r}
#| echo: true

modelo_lm <- 
parsnip::linear_reg() %>%
parsnip::set_engine("lm")

modelo_lm

```

## Creación y ajuste de modelos en un conjunto de entrenamiento

```{r}
#| echo: true

workflow_lm <-
workflow() %>% 
workflows::add_recipe(receta_pinguinos) %>% 
workflows::add_model(modelo_lm) 
 
ajuste_lm <- fit(workflow_lm, pinguinos_entrenamiento)

ajuste_lm

```

## Evaluación de los modelos según los parámetros seleccionados

Usando el paquete `broom`

```{r}
#| echo: true

ajuste_lm %>% tidy()

```

## Perfeccionamiento de los modelos

1.  Realizar el ajuste de hiperparámetros
2.  Hacerlo mediante validación cruzada

## Perfeccionamiento de los modelos

1.  Realizar el ajuste de hiperparámetros
2.  Hacerlo mediante validación cruzada

![](img/cv_five.png){fig-align="center"}
https://stats.stackexchange.com/questions/595512/

## Perfeccionamiento de los modelos

1.  Realizar el ajuste de hiperparámetros
2.  Hacerlo mediante validación cruzada

`tidymodels` tiene dos paquetes para ayudarnos con estos pasos: `tune` y `rsample`

:::: {.columns}

::: {.column width="50%"}

```{r}
#| echo: true
# modelo lm()
modelo_lm <- 
parsnip::linear_reg() %>%
parsnip::set_engine("lm")

modelo_lm

```
::: 

::: {.column width="50%"}

```{r}
#| echo: true
# modelo glm()
modelo_glm <- 
parsnip::linear_reg(penalty = 0.1,
                    mixture = 0.95) %>%
parsnip::set_engine("glmnet")

modelo_glm

```

::: 
  
:::: 

## Perfeccionamiento de los modelos

:::: {.columns}

::: {.column width="50%"}

```{r}
#| echo: true
# modelo glm()
modelo_glm <- 
parsnip::linear_reg(penalty = 0.1,
                    mixture = 0.95) %>%
parsnip::set_engine("glmnet")

modelo_glm
```
::: 

::: {.column width="50%"}

```{r}
#| echo: true
# creamos grilla de valores a testear

penalty_tune <- 10^seq(-3, 0,
                       length.out = 10)

grilla <- crossing(penalty = penalty_tune,
                   mixture = c(0.1, 1.0))
```

::: 
  
:::: 

## Perfeccionamiento de los modelos

```{r}
#| echo: true
# creamos grilla de valores a testear

penalty_tune

grilla 

```

## Perfeccionamiento de los modelos

A continuación, debemos especificar cómo realizaremos la validación cruzada. Desde el paquete paquete `rsample`, podemos utilizar la función `vfold_cv`

```{r}
#| echo: true
# creamos el seteo de crossvalidation


pinguinos_folds <- vfold_cv(pinguinos_entrenamiento, v = 5)
pinguinos_folds

```

## Perfeccionamiento de los modelos

Ahora creamos un modelo "tuneable"

:::: {.columns}

::: {.column width="50%"}

```{r}
#| echo: true
# modelo glm() con hiperparametros fijos
modelo_glm <- 
parsnip::linear_reg(penalty = 0.1,
                    mixture = 0.95) %>%
parsnip::set_engine("glmnet")

modelo_glm

```
::: 

::: {.column width="50%"}

```{r}
#| echo: true
# modelo glm() con hiperparametros tuneables
modelo_glm_tune <- 
  linear_reg(penalty = tune(),
             mixture = tune()) %>% 
  set_engine("glmnet",
             path_values = penalty_tune)

modelo_glm_tune

```

::: 
  
:::: 

## Perfeccionamiento de los modelos
```{r}
#| echo: true
# modelo glm() con hiperparametros tuneables

workflow_glm_tune <- 
workflow() %>% 
  workflows::add_recipe(receta_pinguinos) %>% 
  workflows::add_model(modelo_glm_tune) 

```

```{r}
#| echo: true
# tuneamos el modelo glm

glm_tuned <- tune_grid(
  # el workflow para tunear
  workflow_glm_tune, 
  # los "folds"
  resamples = pinguinos_folds,
  # La grilla de hiperparametros
  grid = grilla)
```

## Perfeccionamiento de los modelos
```{r}
#| echo: true
glm_tuned
```

## Perfeccionamiento de los modelos
```{r}
#| echo: true
autoplot(glm_tuned)
```

## Perfeccionamiento de los modelos
```{r}
#| echo: true
glm_best <- select_best(glm_tuned, metric = "rmse")
glm_best
```

## Evaluación del modelo elegido con el conjunto de testeo

Ya tenemos nuestro mejor modelo `glm_best`, ahora lo utilizaremos en el conjunto de testeo

Primero hacemos nuestro último workflow

```{r}
#| echo: true
glm_best_workflow <- 
  workflow_glm_tune %>%
  finalize_workflow(tibble(penalty = 1,
                           mixture = 0.1)) %>%
  fit(data = pinguinos_entrenamiento)

glm_best_workflow 
```

## Evaluación del modelo elegido con el conjunto de testeo

Ya tenemos nuestro mejor modelo `glm_best`, ahora lo utilizaremos en el conjunto de testeo

Primero hacemos nuestro último workflow

```{r}
#| echo: true

glm_best_workflow %>% tidy()

```

## Evaluación del modelo elegido con el conjunto de testeo

Ya tenemos nuestro mejor modelo `glm_best`, ahora lo utilizaremos en el conjunto de testeo

Ahora usamos el conjunto de testeo

```{r}
#| echo: true

last_fit_glm <- last_fit(glm_best_workflow, pinguinos_division)

last_fit_glm %>% collect_metrics()
```

## Evaluación del modelo elegido con el conjunto de testeo

Ya tenemos nuestro mejor modelo `glm_best`, ahora lo utilizaremos en el conjunto de testeo

Ahora usamos el conjunto de testeo


```{r}
#| echo: true

last_fit_glm %>% collect_predictions()
```


## Evaluación del modelo elegido con el conjunto de testeo

Graficamos los resultados del set de testeo

```{r}
#| echo: true
#| output-location: slide

last_fit_glm %>% 
      collect_predictions() %>%
      ggplot(aes(x = masa_corporal_g,
                 y = .pred)) +
      geom_abline(lty = 2, color = "purple", size = 2) +
      geom_point(alpha = 0.3) +
      labs(
      x = "masa corporal en gramos",
      y = "masa predicha",
      title = "Predicción masa pinguinos",
      subtitle = "Análisis en el set de testeo usando modelo glm"
      ) +
  theme_bw()
```

## Este taller fue introductorio, otras capacidades de tidymodels :computer:

::: {.incremental}
- {{< fa brands r-project size=1.4xl >}} **Comparación entre diferentes modelos**: workflows y workflowset son paquetes que facilitan este análisis.
- {{< fa brands r-project size=1.4xl >}} **Interpretación de modelos y sus variables**: importancia de variables, como en modelos de random forest, redes neuronales y otros. 

:::

# Muchas gracias por su atención :heart:

{{< fa brands twitter size=1.4xl >}} [saryace](https://github.com/Saryace) | {{< fa brands github size=1.4xl >}} [Saryace](https://twitter.com/saryace) | {{< fa globe size=1.4xl >}} [saryace.github.io](saryace.github.io)

